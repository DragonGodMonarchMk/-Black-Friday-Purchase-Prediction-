{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c770950f",
   "metadata": {},
   "source": [
    "\n",
    "# Black Friday Purchase Prediction — PyCaret-Free (scikit-learn) Version\n",
    "\n",
    "This notebook replaces **PyCaret** with a **pure scikit-learn + model zoo** workflow so it runs on **Python 3.10 / 3.11 / 3.12**.\n",
    "It auto-detects numeric vs categorical columns, builds robust preprocessing with `ColumnTransformer`, evaluates a set of models,\n",
    "compares metrics (RMSE, MAE, R²), picks the best model, and generates predictions.\n",
    "\n",
    "> **Assumptions:**  \n",
    "> - Target column is **`Purchase`** (change `TARGET_COL` below if different).  \n",
    "> - Training data path is `train.csv` in the same folder as this notebook.  \n",
    "> - Optional libraries (XGBoost, LightGBM, CatBoost) are used **if installed**; otherwise they are skipped automatically.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c37700f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python: 3.9.12 | xgboost=False | lightgbm=False | catboost=False\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ✅ Works on Python 3.10+; no PyCaret required.\n",
    "import sys, os, warnings, math, json\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "# Core regressors\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, ExtraTreesRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "# Optional: XGBoost / LightGBM / CatBoost (used if available)\n",
    "xgb_available = lgb_available = ctb_available = False\n",
    "try:\n",
    "    from xgboost import XGBRegressor\n",
    "    xgb_available = True\n",
    "except Exception as e:\n",
    "    XGBRegressor = None\n",
    "\n",
    "try:\n",
    "    from lightgbm import LGBMRegressor\n",
    "    lgb_available = True\n",
    "except Exception as e:\n",
    "    LGBMRegressor = None\n",
    "\n",
    "try:\n",
    "    from catboost import CatBoostRegressor\n",
    "    ctb_available = True\n",
    "except Exception as e:\n",
    "    CatBoostRegressor = None\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "np.random.seed(RANDOM_STATE)\n",
    "print(f\"Python: {sys.version.split()[0]} | xgboost={xgb_available} | lightgbm={lgb_available} | catboost={ctb_available}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b2104f7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(550068, 12)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User_ID</th>\n",
       "      <th>Product_ID</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Occupation</th>\n",
       "      <th>City_Category</th>\n",
       "      <th>Stay_In_Current_City_Years</th>\n",
       "      <th>Marital_Status</th>\n",
       "      <th>Product_Category_1</th>\n",
       "      <th>Product_Category_2</th>\n",
       "      <th>Product_Category_3</th>\n",
       "      <th>Purchase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000001</td>\n",
       "      <td>P00069042</td>\n",
       "      <td>F</td>\n",
       "      <td>0-17</td>\n",
       "      <td>10</td>\n",
       "      <td>A</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000001</td>\n",
       "      <td>P00248942</td>\n",
       "      <td>F</td>\n",
       "      <td>0-17</td>\n",
       "      <td>10</td>\n",
       "      <td>A</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>15200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1000001</td>\n",
       "      <td>P00087842</td>\n",
       "      <td>F</td>\n",
       "      <td>0-17</td>\n",
       "      <td>10</td>\n",
       "      <td>A</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1000001</td>\n",
       "      <td>P00085442</td>\n",
       "      <td>F</td>\n",
       "      <td>0-17</td>\n",
       "      <td>10</td>\n",
       "      <td>A</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>14.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1000002</td>\n",
       "      <td>P00285442</td>\n",
       "      <td>M</td>\n",
       "      <td>55+</td>\n",
       "      <td>16</td>\n",
       "      <td>C</td>\n",
       "      <td>4+</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7969</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   User_ID Product_ID Gender   Age  Occupation City_Category  \\\n",
       "0  1000001  P00069042      F  0-17          10             A   \n",
       "1  1000001  P00248942      F  0-17          10             A   \n",
       "2  1000001  P00087842      F  0-17          10             A   \n",
       "3  1000001  P00085442      F  0-17          10             A   \n",
       "4  1000002  P00285442      M   55+          16             C   \n",
       "\n",
       "  Stay_In_Current_City_Years  Marital_Status  Product_Category_1  \\\n",
       "0                          2               0                   3   \n",
       "1                          2               0                   1   \n",
       "2                          2               0                  12   \n",
       "3                          2               0                  12   \n",
       "4                         4+               0                   8   \n",
       "\n",
       "   Product_Category_2  Product_Category_3  Purchase  \n",
       "0                 NaN                 NaN      8370  \n",
       "1                 6.0                14.0     15200  \n",
       "2                 NaN                 NaN      1422  \n",
       "3                14.0                 NaN      1057  \n",
       "4                 NaN                 NaN      7969  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# === Load data ===\n",
    "DATA_PATH = 'train.csv'  # Change if your file is elsewhere\n",
    "TARGET_COL = 'Purchase'  # Change if your target is different\n",
    "\n",
    "df = pd.read_csv(r\"C:\\Users\\dell\\Downloads\\Black Friday EDA + Prediction\\train.csv\\train.csv\")\n",
    "print(df.shape)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "17a318c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>unique</th>\n",
       "      <th>top</th>\n",
       "      <th>freq</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>User_ID</th>\n",
       "      <td>550068.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1003028.842401</td>\n",
       "      <td>1727.591586</td>\n",
       "      <td>1000001.0</td>\n",
       "      <td>1001516.0</td>\n",
       "      <td>1003077.0</td>\n",
       "      <td>1004478.0</td>\n",
       "      <td>1006040.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Product_ID</th>\n",
       "      <td>550068</td>\n",
       "      <td>3631</td>\n",
       "      <td>P00265242</td>\n",
       "      <td>1880</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gender</th>\n",
       "      <td>550068</td>\n",
       "      <td>2</td>\n",
       "      <td>M</td>\n",
       "      <td>414259</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age</th>\n",
       "      <td>550068</td>\n",
       "      <td>7</td>\n",
       "      <td>26-35</td>\n",
       "      <td>219587</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Occupation</th>\n",
       "      <td>550068.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.076707</td>\n",
       "      <td>6.52266</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>City_Category</th>\n",
       "      <td>550068</td>\n",
       "      <td>3</td>\n",
       "      <td>B</td>\n",
       "      <td>231173</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Stay_In_Current_City_Years</th>\n",
       "      <td>550068</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>193821</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Marital_Status</th>\n",
       "      <td>550068.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.409653</td>\n",
       "      <td>0.49177</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Product_Category_1</th>\n",
       "      <td>550068.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.40427</td>\n",
       "      <td>3.936211</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Product_Category_2</th>\n",
       "      <td>376430.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.842329</td>\n",
       "      <td>5.08659</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Product_Category_3</th>\n",
       "      <td>166821.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.668243</td>\n",
       "      <td>4.125338</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Purchase</th>\n",
       "      <td>550068.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9263.968713</td>\n",
       "      <td>5023.065394</td>\n",
       "      <td>12.0</td>\n",
       "      <td>5823.0</td>\n",
       "      <td>8047.0</td>\n",
       "      <td>12054.0</td>\n",
       "      <td>23961.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               count unique        top    freq  \\\n",
       "User_ID                     550068.0    NaN        NaN     NaN   \n",
       "Product_ID                    550068   3631  P00265242    1880   \n",
       "Gender                        550068      2          M  414259   \n",
       "Age                           550068      7      26-35  219587   \n",
       "Occupation                  550068.0    NaN        NaN     NaN   \n",
       "City_Category                 550068      3          B  231173   \n",
       "Stay_In_Current_City_Years    550068      5          1  193821   \n",
       "Marital_Status              550068.0    NaN        NaN     NaN   \n",
       "Product_Category_1          550068.0    NaN        NaN     NaN   \n",
       "Product_Category_2          376430.0    NaN        NaN     NaN   \n",
       "Product_Category_3          166821.0    NaN        NaN     NaN   \n",
       "Purchase                    550068.0    NaN        NaN     NaN   \n",
       "\n",
       "                                      mean          std        min        25%  \\\n",
       "User_ID                     1003028.842401  1727.591586  1000001.0  1001516.0   \n",
       "Product_ID                             NaN          NaN        NaN        NaN   \n",
       "Gender                                 NaN          NaN        NaN        NaN   \n",
       "Age                                    NaN          NaN        NaN        NaN   \n",
       "Occupation                        8.076707      6.52266        0.0        2.0   \n",
       "City_Category                          NaN          NaN        NaN        NaN   \n",
       "Stay_In_Current_City_Years             NaN          NaN        NaN        NaN   \n",
       "Marital_Status                    0.409653      0.49177        0.0        0.0   \n",
       "Product_Category_1                 5.40427     3.936211        1.0        1.0   \n",
       "Product_Category_2                9.842329      5.08659        2.0        5.0   \n",
       "Product_Category_3               12.668243     4.125338        3.0        9.0   \n",
       "Purchase                       9263.968713  5023.065394       12.0     5823.0   \n",
       "\n",
       "                                  50%        75%        max  \n",
       "User_ID                     1003077.0  1004478.0  1006040.0  \n",
       "Product_ID                        NaN        NaN        NaN  \n",
       "Gender                            NaN        NaN        NaN  \n",
       "Age                               NaN        NaN        NaN  \n",
       "Occupation                        7.0       14.0       20.0  \n",
       "City_Category                     NaN        NaN        NaN  \n",
       "Stay_In_Current_City_Years        NaN        NaN        NaN  \n",
       "Marital_Status                    0.0        1.0        1.0  \n",
       "Product_Category_1                5.0        8.0       20.0  \n",
       "Product_Category_2                9.0       15.0       18.0  \n",
       "Product_Category_3               14.0       16.0       18.0  \n",
       "Purchase                       8047.0    12054.0    23961.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Null counts (top 20):\n",
      " Product_Category_3            383247\n",
      "Product_Category_2            173638\n",
      "User_ID                            0\n",
      "Product_ID                         0\n",
      "Age                                0\n",
      "Gender                             0\n",
      "Occupation                         0\n",
      "City_Category                      0\n",
      "Marital_Status                     0\n",
      "Stay_In_Current_City_Years         0\n",
      "Product_Category_1                 0\n",
      "Purchase                           0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Quick overview\n",
    "display(df.describe(include='all').transpose().head(20))\n",
    "print(\"\\nNull counts (top 20):\\n\", df.isna().sum().sort_values(ascending=False).head(20))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4e9c2839",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numeric cols: 6 | Categorical cols: 5\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# === Features / Target split ===\n",
    "assert TARGET_COL in df.columns, f\"Target column '{TARGET_COL}' not found in data!\"\n",
    "y = df[TARGET_COL]\n",
    "X = df.drop(columns=[TARGET_COL])\n",
    "\n",
    "# Identify column types\n",
    "num_cols = X.select_dtypes(include=['int64', 'float64', 'int32', 'float32']).columns.tolist()\n",
    "cat_cols = X.select_dtypes(include=['object', 'category', 'bool']).columns.tolist()\n",
    "\n",
    "print(f\"Numeric cols: {len(num_cols)} | Categorical cols: {len(cat_cols)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9d4d38d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# === Preprocessing pipelines ===\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler(with_mean=True, with_std=True))\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, num_cols),\n",
    "        ('cat', categorical_transformer, cat_cols)\n",
    "    ],\n",
    "    remainder='drop'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d368aa97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models configured: ['LinearRegression', 'Ridge', 'Lasso', 'ElasticNet', 'KNN', 'SVR', 'RandomForest', 'ExtraTrees', 'GradientBoosting']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# === Model zoo (PyCaret-like compare_models) ===\n",
    "models = {\n",
    "    'LinearRegression': LinearRegression(),\n",
    "    'Ridge': Ridge(random_state=RANDOM_STATE),\n",
    "    'Lasso': Lasso(random_state=RANDOM_STATE, max_iter=20000),\n",
    "    'ElasticNet': ElasticNet(random_state=RANDOM_STATE, max_iter=20000),\n",
    "    'KNN': KNeighborsRegressor(n_neighbors=5),\n",
    "    'SVR': SVR(),\n",
    "    'RandomForest': RandomForestRegressor(n_estimators=400, random_state=RANDOM_STATE, n_jobs=-1),\n",
    "    'ExtraTrees': ExtraTreesRegressor(n_estimators=400, random_state=RANDOM_STATE, n_jobs=-1),\n",
    "    'GradientBoosting': GradientBoostingRegressor(random_state=RANDOM_STATE)\n",
    "}\n",
    "\n",
    "if xgb_available:\n",
    "    models['XGBRegressor'] = XGBRegressor(\n",
    "        n_estimators=600, learning_rate=0.05, max_depth=8, subsample=0.8, colsample_bytree=0.8,\n",
    "        random_state=RANDOM_STATE, n_jobs=-1, tree_method='hist'\n",
    "    )\n",
    "if lgb_available:\n",
    "    models['LGBMRegressor'] = LGBMRegressor(\n",
    "        n_estimators=1000, learning_rate=0.05, num_leaves=63, subsample=0.8, colsample_bytree=0.8,\n",
    "        random_state=RANDOM_STATE\n",
    "    )\n",
    "if ctb_available:\n",
    "    models['CatBoostRegressor'] = CatBoostRegressor(\n",
    "        iterations=1000, learning_rate=0.05, depth=8, random_state=RANDOM_STATE, verbose=False\n",
    "    )\n",
    "\n",
    "print(f\"Models configured: {list(models.keys())}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df36358e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# === Train/Test split ===\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "# === Cross-validated comparison ===\n",
    "cv = KFold(n_splits=5, shuffle=True, random_state=RANDOM_STATE)\n",
    "\n",
    "def rmse_cv(estimator, X, y):\n",
    "    # Negative MSE -> take sqrt after negation\n",
    "    scores = cross_val_score(estimator, X, y, scoring='neg_mean_squared_error', cv=cv, n_jobs=-1)\n",
    "    return np.sqrt(-scores)\n",
    "\n",
    "results = []\n",
    "fitted_models = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    pipe = Pipeline(steps=[('preprocess', preprocessor), ('model', model)])\n",
    "    # Compute CV RMSE (primary metric)\n",
    "    cv_rmse = rmse_cv(pipe, X_train, y_train)\n",
    "    results.append({\n",
    "        'model': name,\n",
    "        'cv_rmse_mean': cv_rmse.mean(),\n",
    "        'cv_rmse_std': cv_rmse.std()\n",
    "    })\n",
    "    # Fit on full train\n",
    "    pipe.fit(X_train, y_train)\n",
    "    fitted_models[name] = pipe\n",
    "\n",
    "results_df = pd.DataFrame(results).sort_values('cv_rmse_mean')\n",
    "results_df.reset_index(drop=True, inplace=True)\n",
    "results_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bcfda45",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# === Pick best model (lowest CV RMSE) ===\n",
    "best_name = results_df.iloc[0]['model']\n",
    "best_model = fitted_models[best_name]\n",
    "print(f\"Best model by CV RMSE: {best_name}\")\n",
    "\n",
    "# === Holdout evaluation ===\n",
    "preds = best_model.predict(X_test)\n",
    "rmse = mean_squared_error(y_test, preds, squared=False)\n",
    "mae = mean_absolute_error(y_test, preds)\n",
    "r2 = r2_score(y_test, preds)\n",
    "print({\"RMSE\": rmse, \"MAE\": mae, \"R2\": r2})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5e04df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# === Feature importance (tree-based only) ===\n",
    "import numpy as np\n",
    "try:\n",
    "    model_step = best_model.named_steps['model']\n",
    "    preprocess_step = best_model.named_steps['preprocess']\n",
    "    # Extract feature names post-encoding\n",
    "    ohe = preprocess_step.named_transformers_['cat'].named_steps['onehot']\n",
    "    cat_feature_names = ohe.get_feature_names_out(preprocess_step.transformers_[1][2])\n",
    "    num_feature_names = preprocess_step.transformers_[0][2]\n",
    "    feature_names = np.concatenate([num_feature_names, cat_feature_names])\n",
    "\n",
    "    if hasattr(model_step, 'feature_importances_'):\n",
    "        importances = model_step.feature_importances_\n",
    "        fi = pd.DataFrame({'feature': feature_names, 'importance': importances}).sort_values('importance', ascending=False).head(30)\n",
    "        display(fi)\n",
    "    else:\n",
    "        print(\"Best model doesn't expose feature_importances_. Skipping.\")\n",
    "except Exception as e:\n",
    "    print(\"Feature importance extraction skipped:\", e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3240df41",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# === Save results and model ===\n",
    "import joblib, json, os\n",
    "\n",
    "os.makedirs('artifacts', exist_ok=True)\n",
    "results_df.to_csv('artifacts/model_comparison.csv', index=False)\n",
    "joblib.dump(best_model, 'artifacts/best_model.joblib')\n",
    "\n",
    "summary = {\n",
    "    'best_model': str(best_model),\n",
    "    'holdout': {'rmse': float(rmse), 'mae': float(mae), 'r2': float(r2)},\n",
    "    'models_tried': results_df['model'].tolist()\n",
    "}\n",
    "with open('artifacts/summary.json', 'w') as f:\n",
    "    json.dump(summary, f, indent=2)\n",
    "\n",
    "print(\"Saved: artifacts/model_comparison.csv, artifacts/best_model.joblib, artifacts/summary.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a359cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# === Inference example ===\n",
    "# To use the trained best model on new data (same schema as X):\n",
    "# new_data = pd.read_csv('test.csv')\n",
    "# preds_new = best_model.predict(new_data)\n",
    "# pd.DataFrame({'Prediction': preds_new}).to_csv('artifacts/test_predictions.csv', index=False)\n",
    "# print('Saved: artifacts/test_predictions.csv')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
